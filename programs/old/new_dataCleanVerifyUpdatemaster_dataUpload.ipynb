{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preamble: This script is used to clean and insert monthly asset ledger data into a PostgreSQL database.\n",
    "import pandas as pd\n",
    "import os\n",
    "import psycopg2\n",
    "from sqlalchemy import create_engine\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv(r'C:\\Users\\Lane\\Documents\\Projects\\trading_bot\\programs\\server_credentials.env')\n",
    "file_path = r'C:\\\\Users\\\\Lane\\\\Documents\\\\Projects\\\\trading_bot\\\\data\\\\old data\\\\Accounts_History_2023.csv'  # Update this path as needed\n",
    "data = pd.read_csv(file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1: Clean and Format the Data\n",
    "data = data.apply(lambda x: x.str.strip() if x.dtype == \"object\" else x)\n",
    "data = data.dropna(subset=['Symbol'])  # 'Symbol' is renamed to 'symbol' \n",
    "rename_columns = {\n",
    "    'Run Date': 'transaction_date',\n",
    "    'Account': 'portfolio_name',\n",
    "    'Action': 'notes',\n",
    "    'Symbol': 'symbol',\n",
    "    'Description': 'asset_name',\n",
    "    'Quantity': 'quantity',\n",
    "    'Price': 'price',\n",
    "    'Amount': 'transaction_amount',\n",
    "    'Commission': 'commission',\n",
    "    'Fees': 'fees'\n",
    "}\n",
    "data = data.rename(columns=rename_columns)\n",
    "data['commission'] = data['commission'].fillna(0)\n",
    "data['fees'] = data['fees'].fillna(0)\n",
    "columns_to_delete = [\n",
    "    'Type', 'Exchange Quantity', 'Exchange Currency', 'Currency', \n",
    "    'Exchange Rate', 'Accrued Interest', 'Settlement Date'\n",
    "]\n",
    "data = data.drop(columns=columns_to_delete, errors='ignore')\n",
    "final_columns_order = [\n",
    "    'symbol', 'asset_name', 'quantity', 'price', 'transaction_amount', \n",
    "    'commission', 'fees', 'portfolio_name', 'transaction_date', 'notes'\n",
    "]\n",
    "data = data[final_columns_order]\n",
    "data['transaction_date'] = pd.to_datetime(data['transaction_date'], format='%m/%d/%Y').dt.strftime('%Y-%m-%d')\n",
    "data['symbol'] = data['symbol'].str.lstrip('-')\n",
    "\n",
    "# Generate a report called: 'report-cleaned_' + file_name\n",
    "cleaned_file_path = os.path.splitext(file_path)[0] + '_cleaned.csv'\n",
    "data.to_csv(cleaned_file_path, index=False)\n",
    "print(f\"Cleaned file saved as: {cleaned_file_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 2: Verify on yfinance the status of the symbols and generate a report called: 'master_data69_verification'\n",
    "import pandas as pd\n",
    "import yfinance as yf\n",
    "from datetime import datetime, timedelta\n",
    "import re\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "import time\n",
    "\n",
    "# ======= Configuration Section =======\n",
    "# Define the expected master data file and output file paths\n",
    "master_data_file = r'C:\\Users\\Lane\\Documents\\Projects\\trading_bot\\programs\\master_data14.csv'\n",
    "output_path = r'C:\\Users\\Lane\\Documents\\Projects\\trading_bot\\data\\old data\\report-weekly_symbol_status.csv'\n",
    "verified_delisted_list = {\"SRCL\", \"STER\"}  # Verified Delisted List\n",
    "# =====================================\n",
    "\n",
    "# Edits to make: Add new symbols in 'report-cleaned' file from step 1 to the master_data file\n",
    "\n",
    "# Set the date threshold dynamically to 3 days before the current date\n",
    "last_known_trading_date = datetime.now() - timedelta(days=3)\n",
    "print(f\"Checking for delistings with last trading date on or before: {last_known_trading_date.date()}\")\n",
    "\n",
    "# Function to check if a ticker is a mutual fund using metadata from yfinance\n",
    "def is_mutual_fund(ticker):\n",
    "    stock = yf.Ticker(ticker)\n",
    "    asset_type = stock.info.get(\"quoteType\", \"\")\n",
    "    return asset_type == \"MUTUALFUND\"\n",
    "\n",
    "# Function to process tickers, handling cases where they start with a dash and include additional characters\n",
    "def check_ticker_status(ticker, max_retries=3, delay=2):\n",
    "    # Handle tickers that start with a dash by extracting the symbol\n",
    "    if ticker.startswith('-'):\n",
    "        # Remove the dash and capture the initial letters of the symbol (e.g., \"-ABC123\" becomes \"ABC\")\n",
    "        match = re.match(r'-([A-Za-z]+)', ticker)\n",
    "        if match:\n",
    "            ticker = match.group(1)\n",
    "            tqdm.write(f\"Adjusted ticker to '{ticker}' for lookup\")\n",
    "\n",
    "    # Check if ticker is in Verified Delisted List\n",
    "    if ticker in verified_delisted_list:\n",
    "        message = f\"{ticker}: Verified Delisted\"\n",
    "        tqdm.write(message)\n",
    "        return \"Verified Delisted\"\n",
    "\n",
    "    try:\n",
    "        # Check if ticker resembles an options contract\n",
    "        if re.search(r'-\\w+\\d+', ticker):\n",
    "            return \"Options Contract\"\n",
    "\n",
    "        # Check if ticker is a string of letters and numbers, indicating a 'Bought Out' case\n",
    "        if re.match(r'^\\d+[A-Z]+\\d+$', ticker):\n",
    "            return \"Bought Out\"\n",
    "\n",
    "        # Determine if it's a mutual fund using metadata\n",
    "        stock = yf.Ticker(ticker)\n",
    "        if is_mutual_fund(ticker):\n",
    "            data = stock.history(period=\"1mo\")  # Use 1mo for mutual funds\n",
    "            if not data.empty:\n",
    "                message = f\"{ticker}: Active (Mutual Fund)\"\n",
    "                tqdm.write(message)\n",
    "                return \"Active\"\n",
    "            else:\n",
    "                message = f\"{ticker}: Possibly Delisted (no recent data)\"\n",
    "                tqdm.write(message)\n",
    "                return \"Possibly Delisted\"\n",
    "\n",
    "        # Default handling for regular stocks\n",
    "        data = stock.history(period=\"5d\")  # Default to 5 days for regular stocks\n",
    "\n",
    "        # Retry mechanism to handle intermittent data fetching issues\n",
    "        for attempt in range(max_retries):\n",
    "            if not data.empty:\n",
    "                break\n",
    "            if attempt < max_retries - 1:\n",
    "                time.sleep(delay)\n",
    "                data = stock.history(period=\"5d\")\n",
    "\n",
    "        # If data is still empty after retries, flag as possibly delisted\n",
    "        if data.empty:\n",
    "            return \"Possibly Delisted\"\n",
    "\n",
    "        # Check the last available trading date without implying it's a delisting date match\n",
    "        last_trading_day = data.index[-1] if not data.empty else None\n",
    "        if last_trading_day and last_trading_day.to_pydatetime().date() <= last_known_trading_date.date():\n",
    "            return \"Possibly Delisted\"\n",
    "\n",
    "        # For regular stocks only, check if there is no volume\n",
    "        if data['Volume'].sum() == 0 and not is_mutual_fund(ticker):\n",
    "            return \"Possibly Delisted\"\n",
    "\n",
    "        return \"Active\"\n",
    "\n",
    "    except Exception:\n",
    "        return \"Possibly Delisted\"\n",
    "\n",
    "# Main function to check all symbols in tickers\n",
    "def perform_symbol_activity_check(tickers):\n",
    "    results = {}\n",
    "    start_time = time.time()\n",
    "    progress_bar = tqdm(tickers, desc=\"Checking ticker status\", unit=\"ticker\")\n",
    "\n",
    "    # Calculate velocity and estimated time remaining\n",
    "    for i, ticker in enumerate(progress_bar):\n",
    "        status = check_ticker_status(ticker)\n",
    "        results[ticker] = status\n",
    "\n",
    "        # Only display important statuses, excluding \"Active\"\n",
    "        if status != \"Active\":\n",
    "            tqdm.write(f\"{ticker}: {status}\")\n",
    "\n",
    "        # When 25% progress is reached, estimate time remaining\n",
    "        if i == int(len(tickers) * 0.25):\n",
    "            elapsed_time = time.time() - start_time\n",
    "            velocity = i / elapsed_time\n",
    "            estimated_total_time = len(tickers) / velocity\n",
    "            remaining_time = estimated_total_time - elapsed_time\n",
    "            progress_bar.set_postfix_str(f\"Estimated time left: {int(remaining_time)}s\")\n",
    "\n",
    "        # Update estimated time left dynamically after 25% completion\n",
    "        elif i > int(len(tickers) * 0.25):\n",
    "            elapsed_time = time.time() - start_time\n",
    "            remaining_time = (len(tickers) - i) / velocity\n",
    "            progress_bar.set_postfix_str(f\"Estimated time left: {int(remaining_time)}s\")\n",
    "\n",
    "    return results\n",
    "\n",
    "# Main script execution\n",
    "if __name__ == \"__main__\":\n",
    "    # Check if the expected file exists\n",
    "    if os.path.exists(master_data_file):\n",
    "        # Load tickers from the specified master_data file\n",
    "        master_data = pd.read_csv(master_data_file)\n",
    "        tickers = master_data['symbol'].tolist()\n",
    "        print(f\"Running symbol activity integrity check on tickers from {master_data_file}\")\n",
    "        print(f\"Total tickers loaded: {len(tickers)}\")\n",
    "\n",
    "        # Run the symbol activity check if tickers are loaded\n",
    "        if tickers:\n",
    "            results = perform_symbol_activity_check(tickers)\n",
    "            \n",
    "            # Save results to the specified path\n",
    "            results_df = pd.DataFrame(list(results.items()), columns=['Ticker', 'Status'])\n",
    "            results_df.to_csv(output_path, index=False)\n",
    "            print(f\"Results saved to {output_path}\")\n",
    "    else:\n",
    "        print(f\"Error: Please ensure the file '{master_data_file}' is loaded in the directory.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 3: Insert the cleaned data into the PostgreSQL database\n",
    "import pandas as pd\n",
    "import os\n",
    "from sqlalchemy import create_engine\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# Specify the exact path to your server_credentials.env file\n",
    "load_dotenv(r'C:\\Users\\Lane\\Documents\\Projects\\trading_bot\\programs\\server_credentials.env')\n",
    "\n",
    "# Retrieve database credentials from environment variables\n",
    "db_user = os.getenv('DB_USER')\n",
    "db_password = os.getenv('DB_PASSWORD')\n",
    "db_host = os.getenv('DB_HOST')\n",
    "db_port = os.getenv('DB_PORT')\n",
    "db_name = os.getenv('DB_NAME')\n",
    "\n",
    "engine = create_engine(f'postgresql://{db_user}:{db_password}@{db_host}:{db_port}/{db_name}')\n",
    "\n",
    "file_paths = [\n",
    "    r'C:\\Users\\Lane\\Documents\\Projects\\trading_bot\\data\\Accounts_History_2021_cleaned.csv',\n",
    "    r'C:\\Users\\Lane\\Documents\\Projects\\trading_bot\\data\\Accounts_History_2022_cleaned.csv',\n",
    "    r'C:\\Users\\Lane\\Documents\\Projects\\trading_bot\\data\\Accounts_History_2023_cleaned.csv',\n",
    "    r'C:\\Users\\Lane\\Documents\\Projects\\trading_bot\\data\\Accounts_History_2024_cleaned.csv'\n",
    "]\n",
    "\n",
    "# Purpose: Loop through each file, load it into a DataFrame, and insert it into the asset_ledger table.\n",
    "\n",
    "for file_path in file_paths:\n",
    "    try:\n",
    "        # Load the CSV file into a DataFrame\n",
    "        data = pd.read_csv(file_path)\n",
    "        print(f\"Data loaded from {file_path}.\")\n",
    "        \n",
    "        # Insert Data into Database\n",
    "        with engine.connect() as connection:\n",
    "            data.to_sql('asset_ledger', con=connection, if_exists='append', index=False)\n",
    "        \n",
    "        # Confirm successful insertion\n",
    "        print(f\"Data from {file_path} successfully inserted into the database.\")\n",
    "    \n",
    "    except Exception as e:\n",
    "        # Step 5d: Handle errors during insertion\n",
    "        print(f\"An error occurred during data insertion for {file_path}: {e}\")"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
